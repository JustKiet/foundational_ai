{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LASSO REGRESSION**\n",
    "\n",
    "## **A. CONCEPT**\n",
    "\n",
    "***Lasso Regression*** is a type of linear regression that adds an L1 penalty term to the objective function, encouraging sparsity in the model. The main idea behind Lasso is not to just fit the best possible line (like in standard linear regression) but to also **shrink some of the coefficients towards zero**, eliminating less important features (variables). This makes Lasso particularly useful for feature selection and prevent overfitting.\n",
    "\n",
    "### **1. Objective of Lasso Regression**\n",
    "\n",
    "The goal of Lasso Regression is to minimize the following loss function:\n",
    "\n",
    "$Minimize \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2 + \\lambda \\sum_{j=1}^{p} \\lvert{\\beta_j}\\rvert$\n",
    "\n",
    "where:\n",
    "\n",
    "- $y_i$: the actual value of the i-th observation.\n",
    "- $\\hat{y_i}$: the predicted value for the i-th observation (based on the model).\n",
    "- $\\beta_j$: the model coefficients (parameters/weights).\n",
    "- $\\lambda$: the regularization parameter (controls the strength of the penalty).\n",
    "- $p$: the numbers of features.\n",
    "\n",
    "The first part of the equation $\\sum_{i=1}^{n} (y_i - \\hat{y_i})^2$ is Residual Sum of Squares RSS, which measures how well the model fits the data.\n",
    "\n",
    "The second part $\\lambda \\sum_{j=1}^{p} \\lvert{\\beta_j}\\rvert$ is the **L1 regularization term**, where:\n",
    "\n",
    "- The sum $\\sum_{j=1}^{p} \\lvert{\\beta_j}\\rvert$ is the **L1 norm** of the coefficients, which is the sum of the absolute values of the coefficients.\n",
    "- The regularization $\\lambda$ controls **the degree of shrinkage**: higher values of $\\lambda$ impose stronger regularization (penalizing larger coefficients more), which leads to sparser models (more coefficients set to zero).\n",
    "\n",
    "### **2. Gradient Descent for Lasso Regression**\n",
    "\n",
    "To train Lasso Regression, we need to use Gradient Descent, which update the model parameters iteratively to minimize the cost function.\n",
    "\n",
    "$\\beta_j \\leftarrow \\beta_j$ - \\alpha \\frac{\\partial J(\\beta)}{\\partial \\beta_j}$\n",
    "\n",
    "The Lasso Cost Function is a combination of the quadratic loss function (squared error) and L1 penalty term. To find the gradient (derivative) with respect to the coefficient $\\beta_j$, both components will be calculated seperately.\n",
    "\n",
    "#### *2.1. Derivative of RSS*\n",
    "\n",
    "The RSS cost function is:\n",
    "\n",
    "$RSS = \\sum_{i=1}^{N} (y_i - \\hat{y_i})^2$\n",
    "\n",
    "The derivative of RSS with respect to $\\beta_j$ is:\n",
    "\n",
    "$\\frac{\\partial RSS}{\\partial \\beta_j} = -2 \\sum_{i=1}^{N} x_{ij}$\n",
    "\n",
    "where:\n",
    "- $x_{ij}$: the value of the j-th feature for the i-th observation.\n",
    "- $\\hat{y_i}$: the predicted value for the i-th observation.\n",
    "\n",
    "#### *2.2. Derivative of the L1 Regularization Term:*\n",
    "\n",
    "The L1 regularization term is:\n",
    "\n",
    "$L1 = \\lambda \\sum_{j=1}^{p} \\lvert \\beta_j \\rvert$\n",
    "\n",
    "The derivative of $\\lvert \\beta_j \\rvert$ with respect to $\\beta_j$ is:\n",
    "\n",
    "$\\frac{\\partial \\lvert \\beta_j \\rvert}{\\partial \\beta_j} = sgn(\\beta_j)$\n",
    "\n",
    "where $sgn(\\beta_j)$ is the **sign function**:\n",
    "\n",
    "$sgn(\\beta_j) = \\begin{Bmatrix} 1 & if & \\beta_j > 0\\\\ -1 & if & \\beta_j < 0\\\\ 0 & if & \\beta_j = 0\\end{Bmatrix}$\n",
    "\n",
    "So, the derivative of the L1 regularization term with respect to $\\beta_j$ is:\n",
    "\n",
    "$\\frac{\\partial L1}{\\partial \\beta_j} = \\lambda sgn(\\beta_j)$\n",
    "\n",
    "#### *2.3. Gradient of Lasso Cost Function*\n",
    "\n",
    "Combining the Derivative of RSS and the Derivative of the L1 Regularization Term, we get the Gradient of Lasso Cost Function:\n",
    "\n",
    "$\\frac{\\partial J(\\beta)}{\\partial \\beta_j} = -2 \\sum_{i=1}^{N} (y_i - \\hat{y_i})x_{ij} + \\lambda sgn(\\beta_j)$\n",
    "\n",
    "where:\n",
    "- The first term comes from RSS (squared error).\n",
    "- The second term comes from the L1 Regularization.\n",
    "\n",
    "### **3. Lasso vs Ridge**\n",
    "\n",
    "- **Ridge**: Uses an **L2 penalty** (sum of squared coefficients). Ridge tends to shrink coefficients but does not set them to zero, making all features stay remained in the model.\n",
    "\n",
    "- **Lasso**: Uses an **L1 penalty** (sum of absolute coefficients), which can shrink coefficients to *exactly zero*, making Lasso a good choice for feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **B. IMPLEMENTATIONS**\n",
    "\n",
    "### **0. Preparing data**\n",
    "\n",
    "The dataset for implementing LASSO is going to be the **Auto MPG Dataset**\n",
    "\n",
    "This dataset contains data on the fuel consumption (miles per gallon) of various car models, along with other attributes like engine displacement, horsepower, weight, acceleration, and model year.\n",
    "\n",
    "- **Dataset Source**: Auto MPG Dataset\n",
    "\n",
    "- **Labels**: Continuous values representing miles per gallon (mpg).\n",
    "\n",
    "- **Scope**: Covers different car models with attributes such as engine displacement, horsepower, and weight.\n",
    "\n",
    "- **Size**: 398 samples, each with 8 attributes.\n",
    "\n",
    "- **Language**: N/A (numerical data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependecies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
       "0  18.0          8         307.0        130    3504          12.0          70   \n",
       "1  15.0          8         350.0        165    3693          11.5          70   \n",
       "2  18.0          8         318.0        150    3436          11.0          70   \n",
       "3  16.0          8         304.0        150    3433          12.0          70   \n",
       "4  17.0          8         302.0        140    3449          10.5          70   \n",
       "\n",
       "   origin                   car name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "DATA_PATH = 'data/auto-mpg[1].csv'\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0          8         307.0        130    3504          12.0          70   \n",
      "1          8         350.0        165    3693          11.5          70   \n",
      "2          8         318.0        150    3436          11.0          70   \n",
      "3          8         304.0        150    3433          12.0          70   \n",
      "4          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   origin  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1   \n",
      " (392, 7)\n",
      "0    18.0\n",
      "1    15.0\n",
      "2    18.0\n",
      "3    16.0\n",
      "4    17.0\n",
      "Name: mpg, dtype: float64 \n",
      " (392,)\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "# Dropping car name column\n",
    "data = data.drop('car name', axis=1) if 'car name' in data.columns else data\n",
    "\n",
    "# Dropping rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Dropping rows with \"?\" values\n",
    "data = data[data.horsepower != '?']\n",
    "\n",
    "# Splitting the data into features and target\n",
    "X = data.drop('mpg', axis=1)\n",
    "y = data['mpg']\n",
    "\n",
    "print(X.head(), \"\\n\", X.shape)\n",
    "print(y.head(), \"\\n\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape: (313, 7)\n",
      "X_test Shape: (79, 7)\n",
      "y_train Shape: (313,)\n",
      "y_test Shape: (79,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train Shape: {X_train.shape}\") \n",
    "print(f\"X_test Shape: {X_test.shape}\")\n",
    "print(f\"y_train Shape: {y_train.shape}\") \n",
    "print(f\"y_test Shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0          8         307.0        130    3504          12.0          70   \n",
      "1          8         350.0        165    3693          11.5          70   \n",
      "2          8         318.0        150    3436          11.0          70   \n",
      "3          8         304.0        150    3433          12.0          70   \n",
      "4          8         302.0        140    3449          10.5          70   \n",
      "\n",
      "   origin  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1   \n",
      " (392, 7)\n",
      "0    18.0\n",
      "1    15.0\n",
      "2    18.0\n",
      "3    16.0\n",
      "4    17.0\n",
      "Name: mpg, dtype: float64 \n",
      " (392,)\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X)\n",
    "X_test = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y.values.reshape(-1, 1)).squeeze()\n",
    "y_test = scaler_y.transform(y_test.values.reshape(-1, 1)).squeeze()\n",
    "\n",
    "print(X[:5], \"\\n\", X.shape)\n",
    "print(y[:5], \"\\n\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of features:  [-1.08756541e-16 -7.25043608e-17 -1.81260902e-16 -1.81260902e-17\n",
      "  4.35026165e-16 -1.16006977e-15  1.35945676e-16]\n",
      "Standard deviation of features:  [1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Checking the mean and standard deviation of the features\n",
    "print(\"Mean of features: \", X_train.mean(axis=0))\n",
    "print(\"Standard deviation of features: \", X_train.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 7)\n",
      "(79, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold=1e-5)  # Set a small threshold for near-zero variance\n",
    "X_train = selector.fit_transform(X_train)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Training model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up hyperparameters\n",
    "EPOCHS = 1000\n",
    "LAMBDA = 0.1\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.48394702  1.07728956  0.66413273  0.62054034 -1.285258\n",
      "  -1.62531533 -0.71664105]\n",
      " [ 1.          1.48394702  1.48873169  1.57459447  0.84333403 -1.46672362\n",
      "  -1.62531533 -0.71664105]\n",
      " [ 1.          1.48394702  1.1825422   1.18439658  0.54038176 -1.64818924\n",
      "  -1.62531533 -0.71664105]\n",
      " [ 1.          1.48394702  1.04858429  1.18439658  0.53684535 -1.285258\n",
      "  -1.62531533 -0.71664105]\n",
      " [ 1.          1.48394702  1.02944745  0.92426466  0.5557062  -1.82965485\n",
      "  -1.62531533 -0.71664105]] \n",
      " (392, 8)\n",
      "[[ 1.         -0.86401356 -0.94164742 -0.92267201 -0.92958509  0.89232939\n",
      "  -1.08169451  0.52638236]\n",
      " [ 1.         -0.86401356 -0.70243687  0.27393484 -0.21523071  0.05758756\n",
      "   0.54916798  0.52638236]\n",
      " [ 1.         -0.86401356 -0.98948953 -1.15679075 -1.38813931  0.31163942\n",
      "   0.54916798  1.76940577]\n",
      " [ 1.         -0.86401356 -0.98948953 -0.89665882 -1.20542491  1.79965748\n",
      "  -1.35350492 -0.71664105]\n",
      " [ 1.         -0.86401356 -0.52063686 -0.48044774 -0.22112473  0.02129443\n",
      "   1.63640964 -0.71664105]] \n",
      " (79, 8)\n"
     ]
    }
   ],
   "source": [
    "# Adding intercept term to X\n",
    "X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train)) if X_train.shape[1] == 7 else X_train\n",
    "X_test = np.hstack((np.ones((X_test.shape[0], 1)), X_test)) if X_test.shape[1] == 7 else X_test\n",
    "\n",
    "print(X_train[:5], \"\\n\", X_train.shape)\n",
    "print(X_test[:5], \"\\n\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing weights\n",
    "np.random.seed(42)\n",
    "beta = np.zeros(X_train.shape[1])\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Cost: 1.0000952498742655\n",
      "Epoch: 100, Cost: 0.8852820688649577\n",
      "Epoch: 200, Cost: 0.7902609792704005\n",
      "Epoch: 300, Cost: 0.7116406718546322\n",
      "Epoch: 400, Cost: 0.6466069493478077\n",
      "Epoch: 500, Cost: 0.5928247744193663\n",
      "Epoch: 600, Cost: 0.5483570715453853\n",
      "Epoch: 700, Cost: 0.5115972530935621\n",
      "Epoch: 800, Cost: 0.48121315311383983\n",
      "Epoch: 900, Cost: 0.456100443046335\n",
      "Final Weights: [-2.32022966e-08 -1.00175289e-01 -1.03725386e-01 -1.00615037e-01\n",
      " -1.11672068e-01  4.85094512e-02  8.61364409e-02  7.47838832e-02]\n",
      "MSE: 0.3727437468362091\n",
      "Time taken: 0.007403850555419922\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descent\n",
    "def lasso_regression(X_train, y_train, beta, LAMBDA, LEARNING_RATE, EPOCHS):\n",
    "    for epoch in range(EPOCHS):\n",
    "        y_pred = np.dot(X_train, beta)  # Predictions\n",
    "        res = y_train - y_pred          # Residuals\n",
    "        \n",
    "        # Gradient computation\n",
    "        gradient = ((-2 / X_train.shape[0]) * np.dot(X_train.T, res)) + (LAMBDA / X_train.shape[0]) * np.sign(beta)\n",
    "        \n",
    "        # Update weights\n",
    "        beta -= LEARNING_RATE * gradient\n",
    "        \n",
    "        # Compute and print cost every 100 epochs\n",
    "        if epoch % 100 == 0:\n",
    "            cost = np.mean(np.square(res)) + LAMBDA * np.linalg.norm(beta, 1)\n",
    "            print(f\"Epoch: {epoch}, Cost: {cost}\")\n",
    "    return beta, cost\n",
    "\n",
    "time_start = time()\n",
    "beta, cost = lasso_regression(X_train, y_train, beta, LAMBDA, LEARNING_RATE, EPOCHS)\n",
    "time_end = time()\n",
    "\n",
    "print(f\"Final Weights: {beta}\")\n",
    "print(f\"MSE: {np.mean(np.square(y_train - np.dot(X_train, beta)))}\")\n",
    "print(f\"Time taken: {time_end - time_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Cost: 0.38965240496977266\n",
      "Epoch: 100, Cost: 0.2967260599039602\n",
      "Epoch: 200, Cost: 0.29161811944441474\n",
      "Epoch: 300, Cost: 0.29080737500056886\n",
      "Epoch: 400, Cost: 0.2906873419685593\n",
      "Epoch: 500, Cost: 0.2906558857750977\n",
      "Epoch: 600, Cost: 0.29057975981634754\n",
      "Epoch: 700, Cost: 0.29063380278603934\n",
      "Epoch: 800, Cost: 0.2905825495441273\n",
      "Epoch: 900, Cost: 0.2906094591164086\n",
      "Final Weights: [ 1.48938300e-05 -9.47859836e-04 -4.91414166e-04 -3.83623248e-02\n",
      " -5.97733640e-01  5.35796403e-04  3.12598907e-01  9.02642658e-02]\n",
      "MSE: 0.186492514248741\n",
      "R-Squared: 0.813507485751259\n",
      "Time taken: 2.1553826332092285\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent\n",
    "def stochastic_lasso_regression(X_train, y_train, beta, LAMBDA, LEARNING_RATE, EPOCHS):\n",
    "    for epoch in range(EPOCHS):\n",
    "        np.random.seed(42)\n",
    "        indices = np.random.permutation(X_train.shape[0])\n",
    "        X_train = X_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "\n",
    "        for i in range(X_train.shape[0]):\n",
    "            # Select a random data point (stochastic)\n",
    "            xi = X_train[i:i+1]\n",
    "            yi = y_train[i:i+1]\n",
    "\n",
    "            y_pred = np.dot(xi, beta)\n",
    "\n",
    "            gradient = (-2 / xi.shape[0]) * np.dot(xi.T, (yi - y_pred)) + (LAMBDA / xi.shape[0]) * np.sign(beta)\n",
    "\n",
    "            beta -= LEARNING_RATE * gradient\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            y_pred = np.dot(X_train, beta)\n",
    "            res = y_train - y_pred\n",
    "            cost = np.mean(np.square(res)) + LAMBDA * np.linalg.norm(beta, 1)\n",
    "            print(f\"Epoch: {epoch}, Cost: {cost}\")\n",
    "\n",
    "    return beta, cost\n",
    "time_start = time()\n",
    "beta, cost = stochastic_lasso_regression(X_train, y_train, beta, LAMBDA, LEARNING_RATE, EPOCHS)\n",
    "time_end = time()\n",
    "print(f\"Final Weights: {beta}\")\n",
    "print(f\"MSE: {np.mean(np.square(y_train - np.dot(X_train, beta)))}\")\n",
    "print(f\"R-Squared: {1 - np.sum(np.square(y_train - np.dot(X_train, beta))) / np.sum(np.square(y_train - np.mean(y_train)))}\")\n",
    "print(f\"Time taken: {time_end - time_start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **C. PUTTING EVERYTHING TOGETHER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Annotated\n",
    "\n",
    "class LassoRegression:\n",
    "    def __init__(self,\n",
    "                 lambda_: Annotated[float, \"Regularization strength\"] = 0.1,\n",
    "                 epochs: Annotated[int, \"Number of training epochs\"] = 1000,\n",
    "                 learning_rate: Annotated[float, \"Learning rate for optimization\"] = 0.001,\n",
    "                 ):\n",
    "        self.lambda_ = lambda_\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        _, n_features = X.shape\n",
    "        self.beta = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        for epoch in range(self.epochs):\n",
    "            self.update_weights(X, y)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                self.cost += self.lambda_ * np.linalg.norm(self.beta, 1)\n",
    "                print(f\"Epoch: {epoch}, Cost: {self.cost}\")\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        return np.dot(X, self.beta)\n",
    "    \n",
    "    def update_weights(self, X: np.ndarray, y: np.ndarray):\n",
    "        n_samples, _ = X.shape\n",
    "        y_pred = np.dot(X, self.beta)\n",
    "        res = y - y_pred\n",
    "\n",
    "        gradient = ((-2 / n_samples) * np.dot(X.T, res)) + (self.lambda_ / n_samples) * np.sign(self.beta)\n",
    "\n",
    "        self.beta -= self.learning_rate * gradient\n",
    "        self.bias -= self.learning_rate * np.mean(res)\n",
    "        self.cost = np.mean(np.square(res)) + self.lambda_ * np.linalg.norm(self.beta, 1)\n",
    "\n",
    "        return self.beta, self.bias, self.cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Cost: 1.000190499748531\n",
      "Epoch: 100, Cost: 0.8944748808130936\n",
      "Epoch: 200, Cost: 0.8077585634135097\n",
      "Epoch: 300, Cost: 0.7367199744720809\n",
      "Epoch: 400, Cost: 0.6786085079094222\n",
      "Epoch: 500, Cost: 0.6311471142772439\n",
      "Epoch: 600, Cost: 0.5924515965367418\n",
      "Epoch: 700, Cost: 0.5609635865152358\n",
      "Epoch: 800, Cost: 0.5353948893672152\n",
      "Epoch: 900, Cost: 0.514681273751248\n",
      "Epoch: 1000, Cost: 0.49794410997113375\n",
      "Epoch: 1100, Cost: 0.4844585281208707\n",
      "Epoch: 1200, Cost: 0.47362699254943597\n",
      "Epoch: 1300, Cost: 0.46495737539795173\n",
      "Epoch: 1400, Cost: 0.45804476693950497\n",
      "Epoch: 1500, Cost: 0.4525563892760035\n",
      "Epoch: 1600, Cost: 0.44821908702781416\n",
      "Epoch: 1700, Cost: 0.4448089576577394\n",
      "Epoch: 1800, Cost: 0.4421427580500389\n",
      "Epoch: 1900, Cost: 0.44007078545251854\n",
      "Epoch: 2000, Cost: 0.43847098199260237\n",
      "Epoch: 2100, Cost: 0.4372440544488312\n",
      "Epoch: 2200, Cost: 0.4363094362539879\n",
      "Epoch: 2300, Cost: 0.4356019480360047\n",
      "Epoch: 2400, Cost: 0.43506903737467734\n",
      "Epoch: 2500, Cost: 0.43466849870293867\n",
      "Epoch: 2600, Cost: 0.43436659110678083\n",
      "Epoch: 2700, Cost: 0.43413648575626607\n",
      "Epoch: 2800, Cost: 0.43395698631223956\n",
      "Epoch: 2900, Cost: 0.4338114752990621\n",
      "Epoch: 3000, Cost: 0.43368704744514763\n",
      "Epoch: 3100, Cost: 0.43357379764652915\n",
      "Epoch: 3200, Cost: 0.4334642367336292\n",
      "Epoch: 3300, Cost: 0.43335281280871\n",
      "Epoch: 3400, Cost: 0.4332355197297306\n",
      "Epoch: 3500, Cost: 0.43310957747734624\n",
      "Epoch: 3600, Cost: 0.4329731717651259\n",
      "Epoch: 3700, Cost: 0.4328252424297835\n",
      "Epoch: 3800, Cost: 0.432665311943981\n",
      "Epoch: 3900, Cost: 0.4324933468919528\n",
      "Epoch: 4000, Cost: 0.4323096464900701\n",
      "Epoch: 4100, Cost: 0.4321147532639271\n",
      "Epoch: 4200, Cost: 0.43190938184665884\n",
      "Epoch: 4300, Cost: 0.4316943625699628\n",
      "Epoch: 4400, Cost: 0.43147059710459157\n",
      "Epoch: 4500, Cost: 0.43123902389158264\n",
      "Epoch: 4600, Cost: 0.4310005915063835\n",
      "Epoch: 4700, Cost: 0.43075623842956867\n",
      "Epoch: 4800, Cost: 0.430506877971878\n",
      "Epoch: 4900, Cost: 0.4302533873276758\n",
      "Epoch: 5000, Cost: 0.42999659991779066\n",
      "Epoch: 5100, Cost: 0.42973730033683083\n",
      "Epoch: 5200, Cost: 0.42947622134710434\n",
      "Epoch: 5300, Cost: 0.4292140424658708\n",
      "Epoch: 5400, Cost: 0.4289513897786856\n",
      "Epoch: 5500, Cost: 0.42868883668227914\n",
      "Epoch: 5600, Cost: 0.4284269053184057\n",
      "Epoch: 5700, Cost: 0.4281660685076052\n",
      "Epoch: 5800, Cost: 0.4279067520306799\n",
      "Epoch: 5900, Cost: 0.4276493371374019\n",
      "Epoch: 6000, Cost: 0.42739416318780676\n",
      "Epoch: 6100, Cost: 0.4271415303524189\n",
      "Epoch: 6200, Cost: 0.42689170231475976\n",
      "Epoch: 6300, Cost: 0.4266449089332269\n",
      "Epoch: 6400, Cost: 0.42640134883047776\n",
      "Epoch: 6500, Cost: 0.4261611918872981\n",
      "Epoch: 6600, Cost: 0.4259245816249892\n",
      "Epoch: 6700, Cost: 0.42569163746587896\n",
      "Epoch: 6800, Cost: 0.42546245686595163\n",
      "Epoch: 6900, Cost: 0.4252371173169949\n",
      "MSE: 0.19947797700492434\n",
      "R-Squared: 0.7625256732512125\n"
     ]
    }
   ],
   "source": [
    "model = LassoRegression(lambda_=0.1, epochs=7000, learning_rate=0.0001)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"MSE: {np.mean(np.square(y_test - y_pred))}\")\n",
    "print(f\"R-Squared: {1 - np.sum(np.square(y_test - y_pred)) / np.sum(np.square(y_test - np.mean(y_test)))}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
